import tensorflow as tf
from keras.models import load_model
from PIL import Image, ImageOps
import numpy as np
import cv2

# Load the model and labels
model = load_model("C:\\Users\\user\\Downloads\\krm\\keras_Model.h5", compile=False)
class_names = open("C:\\Users\\user\\Downloads\\krm\\labels.txt", "r").readlines()

# Create the array of the right shape to feed into the keras model
data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)

# Initialize the video capture object
cap = cv2.VideoCapture(0)

# Continuously capture and classify images
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    # Convert the image to RGB and resize/crop to 224x224
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    image = Image.fromarray(image)
    size = (224, 224)
    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)

    # Turn the image into a numpy array and normalize
    image_array = np.asarray(image)
    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1

    # Load the image into the array
    data[0] = normalized_image_array

    # Predict the class and confidence score
    prediction = model.predict(data)
    index = np.argmax(prediction)
    class_name = class_names[index]
    confidence_score = prediction[0][index]

    # Display the classification result
    cv2.putText(frame, f"Class: {class_name[2:]}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    cv2.putText(frame, f"Confidence Score: {confidence_score:.2f}", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),
                2)


    #discrimination
    dcmn = 0
    if class_name[0] == '0' : #class1일 때
        dcmn = 1
    elif class_name[0] == '1' and confidence_score <= 0.85 : #class2이면서 신뢰도가 떨어질 때
        dcmn = 1
    print(dcmn)

    if dcmn == 1 :
        #main
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        # Get the dimensions of the image
        width, height = image.size

        # Loop through each pixel in the image
        for x in range(width):
            for y in range(height):
                # Get the RGB values of the pixel
                r, g, b = image.getpixel((x, y))

                # Modify the RGB values based on conditions
                if r > g + 20:
                    new_r = r * 1.2
                    new_g = g * 0.8
                    new_b = b
                elif r + 20 < g:
                    new_r = r * 0.8
                    new_g = g * 1.2
                    new_b = b
                else:
                    new_r = r
                    new_g = g
                    new_b = b

                # Set the new RGB values for the pixel
                image.putpixel((x, y), (int(new_r), int(new_g), int(new_b)))

        # Convert the PIL Image back to OpenCV format
        frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    #공통
    cv2.imshow("Real-time classification", frame)

    # Press 'q' to exit
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Release the video capture object and close the window
cap.release()
cv2.destroyAllWindows()
